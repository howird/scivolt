---
aliases:
  - luoPerpetualHumanoidControl2023
authors: Zhengyi Luo, Jinkun Cao, Alexander Winkler, Kris Kitani, Weipeng Xu
citekey: luoPerpetualHumanoidControl2023
status: doing
tags:
  - '#type/paper'
  - '#area/ai/rl/TODO'
title: Perpetual Humanoid Control for Real-time Simulated Avatars
url: ''
year: 2023/09
---

# Perpetual Humanoid Control for Real-time Simulated Avatars

> \[!abstract\]
> We present a physics-based humanoid controller that achieves high-fidelity motion imitation and fault-tolerant behavior in the presence of noisy input (e.g. pose estimates from video or generated from language) and unexpected falls. Our controller scales up to learning ten thousand motion clips without using any external stabilizing forces and learns to naturally recover from fail-state. Given reference motion, our controller can perpetually control simulated avatars without requiring resets. At its core, we propose the progressive multiplicative control policy (PMCP), which dynamically allocates new network capacity to learn harder and harder motion sequences. PMCP allows efficient scaling for learning from large-scale motion databases and adding new tasks, such as fail-state recovery, without catastrophic forgetting. We demonstrate the effectiveness of our controller by using it to imitate noisy poses from video-based pose estimators and language-based motion generators in a live and real-time multi-person avatar use case.

## 3-pass method

### Pass 1

> \[!info\]
>
> - carefully read title, abstract, intro
> - read all headings and subheadings
> - check references for papers that you have read
> - make any relevant comments on the following:
>   - Category: What type of paper is this? A measurement paper? An analysis of an existing system? A description of a research prototype?
>   - Context: Which other papers is it related to? Which theoretical bases were used to analyze the problem?
>   - Correctness: Do the assumptions appear to be valid?
>   - Contributions: What are the paperâ€™s main contributions?
>   - Clarity: Is the paper well written?

#### Abstract & Introduction Summary

##### Abstract

- physics-based humanoid controller that achieves high-fidelity motion imitation and fault-tolerant behavior in the presence of:
  - noisy input (e.g. pose estimates from video or generated from language)
  - unexpected falls
- Our controller scales up to learning ten thousand motion clips
  - at train or test time? !TODO()
- Given a reference motion, can __perpetually__ control simulated avatars
- DOES NOT use external stabilizing forces
- learns to naturally recover from fail-state (NO RESETS NEEDED)
- METHOD: progressive multiplicative control policy (PMCP)
  - which dynamically allocates new network capacity to learn harder and harder motion sequences
  - allows efficient scaling for learning from large-scale motion databases and adding new tasks, such as fail-state recovery, without catastrophic forgetting
- VALIDATION: in a live and real-time multi-person avatar use case: demonstrates the effectiveness of our controller by using it to imitate noisy poses from:
  - video-based pose estimators
  - language-based motion generators

##### Introduction

- CONTEXT:
  - controlling high-DOF humanoids in physics simulation settings is difficult due to small deviations leading to falling and tripping
  - this is problem is exacerbated by noisy pose inputs generated by video pose estimation OR language models
- CHALLENGE: learning a motion imitator (controller) that can reproduce human-like motion for use in simulated humanoids for avatars
- BENCHMARK: AMASS dataset (10 000 clips, 40 hours of motion)
- PAST ATTEMPTS:
  - cannot scale to entire dataset
    - using __larger__ or __mixture of expert__ policies
  - resorted to using __external forces__ to stabilize the humanoid
    - residual force control (RFC) has helped to create motion imitators that can mimic up to 97% of the AMASS dataset
    - external stabilizing forces are not only unrealistic, but also cause avatars to float/fly
  - resort to resetting when failure condition triggered:
    - due to not being robust to noise from video-generated pose estimates
      - which contain: floating, foot sliding, physically impossible poses
- THIS WORK:
  - aims to create a humanoid controller: video observations from a human -> controls physics-simulated human avatar
  - PRODUCT: Perpetual Humanoid Controller (PHC): a __single__ policy that:
    - achieves a high success rate on motion imitation
    - can recover from fail-state naturally
  - METHOD:
    \- progressive multiplicative control policy to learn from ALL motion sequences in the entire AMASS dataset

#### Additional Comments

-

#### Questions to Answer in Following Passes

-

### Pass 2

> \[!info\]
> Pass 2 (1 hour):
>
> - understand figures, graphs, looking for errors
> - read paper with greater care but skip proofs
> - note other significant references you may want to read

### Pass 3

> \[!info\]
> Pass 3 (5 hours):
>
> - essentially re-implement the entire paper
> - identify assumptions in the paper and challenge them
> - consider how you would present each idea

- [INSERT GIT REPO HERE](www.github.com)
  - comment code and make PR

## Distillation

> \[!info\]
> After the 2/3 pass method try and copy and paste the above notes and present them in a more structured manner

### Problem

-

### Key Points

-

### Methodology

-

### Results

-

### Comments and Implications

-
